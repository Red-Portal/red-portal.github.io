<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>Kyurae Kim | Uncertainty Quantification is the Red Herring of Bayesian Machine Learning</title>
    <meta name="author" content="Kyurae  Kim" />
    <meta name="description" content="Kyurae Kim's blog.
" />


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous" />

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/pastie.css" media="none" id="highlight_theme_light" />

    <!-- Styles -->
    <!--  -->
    <link rel="shortcut icon" href="/assets/img/favicon.jpg"/>
    <!--  -->
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://red-portal.github.io/blog/2022/red_herring/">
    
    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/pastie.css" media="none" id="highlight_theme_dark" />

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="https://red-portal.github.io/">Kyurae Kim</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item active">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>

              <!-- Toogle theme mode -->
              <div class="toggle-container">
                <a id="light-toggle">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </a>
              </div>
            </ul>
          </div>
        </div>
      </nav>
    </header>

    <!-- Content -->
    <div class="container mt-5">
      <!-- _layouts/post.html -->

<div class="post">

  <header class="post-header">
    <h1 class="post-title">Uncertainty Quantification is the Red Herring of Bayesian Machine Learning</h1>
    <p class="post-meta">December 11, 2022</p>
    <p class="post-tags">
      <a href="/blog/2022"> <i class="fas fa-calendar fa-sm"></i> 2022 </a>
        ·  
        <a href="/blog/tag/Bayes">
          <i class="fas fa-hashtag fa-sm"></i> Bayes</a>  
          

    </p>
  </header>

  <article class="post-content">
    <h3 id="will-conformal-predictions-replace-bayesian-inference">Will Conformal Predictions Replace Bayesian Inference?</h3>
<p>With the rise of <a href="https://www.youtube.com/watch?v=kSGP4F_ZcBY" target="_blank" rel="noopener noreferrer">conformal predictions</a>, I hear doubts about the Bayesian approach to machine learning.
This is especially true for Bayesian deep learning, where the Bayesian approach is barely making progress to provide a computationally-feasible baseline for predictive uncertainty quantification.</p>

<h3 id="uncertainty-quantification-is-a-red-herring">Uncertainty Quantification is a Red Herring</h3>
<p>The problem I have with these “doubts” about the future of Bayesian machine learning is that they are founded on a false premise.
For me, Bayesian machine learning was never about <strong>predictive</strong> uncertainty quantification.
Okay, maybe the “never” is a bit of a stretch.
But I do feel that there has been too much focus on the predictive uncertainty quantification aspect of Bayesian machine learning that it has completely overtaken the Bayesian cause.</p>

<p>For me, the Bayesian framework provides the following:</p>

<ul>
  <li>Uncertainty estimates of the <em>parameters</em>.</li>
  <li>Uncertainty estimates of the <em>predictions</em>.</li>
  <li>Data-driven regularization through marginalization.</li>
  <li>Principled model comparison through Bayes factors.</li>
  <li>Principled (with principles founded on probability theory) model design.</li>
  <li>Decision-theoretic performance guarantees.</li>
</ul>

<p>Uncertainty quantification is just one of these.
Explaining what each bullet exactly means would be too long to qualify as a blog post.
Nevertheless, let me discuss the third point, “Data-driven regularization through marginalization,” as I believe it is especially important for machine learning.</p>

<h3 id="going-bayesian-improves-accuracy">Going Bayesian Improves Accuracy</h3>
<p>In the Bayesian framework, one makes predictions \(p(y \mid \mathcal{D})\) by marginalizing over the posterior \(p(\theta \mid \mathcal{D})\) such as
\(\begin{equation}
  p(y \mid \mathcal{D}) = \int p\left(y \mid \theta\right) \, p\left( \theta \mid \mathcal{D} \right) \, \mathrm{d}\theta.
\end{equation}\)
Here, \(p(\theta \mid \mathcal{D})\) automatically takes the <em>parameter uncertainty</em> into account, essentially regularizing the prediction.
Thus, assuming the model is sound, fully Bayesian predictions should improve the predictive accuracy compared to naive point estimates.
Personally, whenever a non-Bayesian model receives the Bayesian treatment, I expect the <strong>predictive accuracy to improve</strong>.
In general, I don’t care about the predictive uncertainty, I just expect those numbers to go up!</p>

<p>My favorite examples of this are the classic matrix factorization algorithms.
For example, Bayesian principled component analysis <a class="citation" href="#bishop_bayesian_1998">(Bishop, 1998)</a> and Bayesian non-negative matrix factorization <a class="citation" href="#schmidt_bayesian_2009">(Schmidt et al., 2009)</a> have shown to be straight upgrades from their original maximum-likelihood variants.
This has also been shown for neural networks by non-other than Radford Neal himself <a class="citation" href="#neal_classification_2006">(Neal, 2006)</a>.</p>

<p>For modern deep neural networks, it took some time to figure out whether such improvement could be obtained.
However, with the computational power of Google, Andrew G. Wilson’s group has shown that convolutional neural networks achieve better predictive performance <a class="citation" href="#izmailov_what_2021">(Izmailov et al., 2021)</a>.</p>

<h3 id="conclusions">Conclusions</h3>
<p>Nonetheless, conformal predictions seem to be a promising approach for obtaining predictive uncertainty estimates.
And this is fine; Bayesian machine learning has its unique agenda.
So keep drinking the Bayesian Kool-Aid!</p>

<h2 id="references">References</h2>
<ol class="bibliography">
<li>
<!-- _layouts/bib.html -->

        <!-- Entry bib key -->
        <div id="bishop_bayesian_1998">
        
          <!-- Title -->
          <div class="title"><b>Bayesian PCA</b></div>
          <!-- Author -->
          <div class="author">Christopher Bishop.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Advances in Neural Information Processing Systems</em> 1998
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
</li>
<li>
<!-- _layouts/bib.html -->

        <!-- Entry bib key -->
        <div id="schmidt_bayesian_2009">
        
          <!-- Title -->
          <div class="title"><b>Bayesian Non-Negative Matrix Factorization</b></div>
          <!-- Author -->
          <div class="author">Mikkel N. Schmidt, Ole Winther, and Lars Kai Hansen.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Independent Component Analysis and Signal Separation</em> 2009
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
</li>
<li>
<!-- _layouts/bib.html -->

        <!-- Entry bib key -->
        <div id="neal_classification_2006">
        
          <!-- Title -->
          <div class="title"><b>Classification with Bayesian Neural Networks</b></div>
          <!-- Author -->
          <div class="author">Radford M. Neal.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Machine Learning Challenges: Evaluating Predictive Uncertainty, Visual Object Classification, and Recognising Tectual Entailment</em> 2006
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
          </div>

          
        </div>
</li>
<li>
<!-- _layouts/bib.html -->

        <!-- Entry bib key -->
        <div id="izmailov_what_2021">
        
          <!-- Title -->
          <div class="title"><b>What Are Bayesian Neural Network Posteriors Really Like?</b></div>
          <!-- Author -->
          <div class="author">Pavel Izmailov, Sharad Vikram, Matthew D Hoffman, and Andrew Gordon Gordon Wilson.
          </div>

          <!-- Journal/Book title and date -->
          <div class="periodical">
            <em>In Proceedings of the 38th International Conference on Machine Learning</em>, Jul 2021
          </div>
        
          <!-- Links/Buttons -->
          <div class="links">
            <a href="http://proceedings.mlr.press/v139/izmailov21a/izmailov21a.pdf" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a>
          </div>

          
        </div>
</li>
</ol>

<script src="https://utteranc.es/client.js" repo="Red-Portal/red-portal.github.io" issue-term="title" theme="preferred-color-scheme" crossorigin="anonymous" async="">
</script>


  </article>

</div>

    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        © Copyright 2025 Kyurae  Kim. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="noopener noreferrer">Unsplash</a>.

      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/@popperjs/core@2.11.2/dist/umd/popper.min.js" integrity="sha256-l/1pMF/+J4TThfgARS6KwWrk/egwuVvhRzfLAMQ6Ds4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js" integrity="sha256-SyTu6CwrfOhaznYZPoolVw2rxoY7lKYKQvqbtqN93HI=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script>
  <script src="/assets/js/zoom.js"></script><!-- Load Common JS -->
  <script src="/assets/js/common.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      loader: {load: ['[tex]/upgreek']},
      tex: {
        tags: 'ams',
        packages: {'[+]': ['upgreek']}
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-BYR4L4SWHW"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag() { dataLayer.push(arguments); }
    gtag('js', new Date());
    gtag('config', 'G-BYR4L4SWHW');
  </script>
  </body>
</html>

