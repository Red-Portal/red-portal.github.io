---
---

@article{kim_probabilistic_2020,
  title = {A Probabilistic Machine Learning Approach to Scheduling Parallel Loops with {{Bayesian}} Optimization},
  author = {Kim, Khu-rai and Kim, Youngjae and Park, Sungyong},
  year = {2020},
  pages = {1--1},
  journal = {IEEE Transactions on Parallel and Distributed Systems},
  selected = {true}
}

@article{kim_automatic_2020,
  title = {Automatic Myocardial Segmentation in Dynamic Contrast Enhanced Perfusion {{MRI}} Using {{Monte Carlo}} Dropout in an Encoder-Decoder Convolutional Neural Network},
  author = {Kim, Yoon-Chul and Kim, Khu Rai and Choe, Yeon Hyeon},
  year = {2020},
  month = mar,
  volume = {185},
  pages = {105150},
  journal = {Computer Methods and Programs in Biomedicine},
  language = {en},
  selected = {true}
}

@article{kim_evcmr_2019,
  title={{{EVCMR}}: {{A}} Tool for the Quantitative Evaluation and Visualization of Cardiac {{MRI}} Data},
  shorttitle={{{EVCMR}}},
  author={Kim, Yoon-Chul and Kim, Khu Rai and Choi, Kwanghee and Kim, Minwoo and Chung, Younjoon and Choe, Yeon Hyeon},
  year={2019},
  month=aug,
  volume={111},
  pages={103334},
  journal={Computers in Biology and Medicine},
  language={en},
  selected={true}
}

@article{kim_fast_2021,
  title = {Fast Calculation Software for Modified {{Look}}-{{Locker}} Inversion Recovery ({{MOLLI}}) {{T1}} Mapping},
  author = {Kim, Yoon-Chul and Kim, Khu Rai and Lee, Hyelee and Choe, Yeon Hyeon},
  year = {2021},
  month = dec,
  volume = {21},
  pages = {26},
  abstract = {Abstract                            Background               The purpose of this study was to develop a software tool and evaluate different T1 map calculation methods in terms of computation time in cardiac magnetic resonance imaging.                                         Methods               The modified Look-Locker inversion recovery (MOLLI) sequence was used to acquire multiple inversion time (TI) images for pre- and post-contrast T1 mapping. The T1 map calculation involved pixel-wise curve fitting based on the T1 relaxation model. A variety of methods were evaluated using data from 30 subjects for computational efficiency: MRmap, python Levenberg\textendash Marquardt (LM), python reduced-dimension (RD) non-linear least square, C++ single- and multi-core LM, and C++ single- and multi-core RD.                                         Results               Median (interquartile range) computation time was 126~s (98\textendash 141) for the publicly available software MRmap, 261~s (249\textendash 282) for python LM, 77~s (74\textendash 80) for python RD, 3.4~s (3.1\textendash 3.6) for C++ multi-core LM, and 1.9~s (1.9\textendash 2.0) for C++ multi-core RD. The fastest C++ multi-core RD and the publicly available MRmap showed good agreement of myocardial T1 values, resulting in 95\% Bland\textendash Altman limits of agreement of (-\,0.83 to 0.58~ms) and (-\,6.57 to 7.36~ms) with mean differences of -\,0.13~ms and 0.39~ms, for the pre- and post-contrast, respectively.                                         Conclusion               The C++ multi-core RD was the fastest method on a regular eight-core personal computer for pre- or post-contrast T1 map calculation. The presented software tool (fT1fit) facilitated rapid T1 map and extracellular volume fraction map calculations.},
  file = {/home/msca8h/Zotero/storage/H54N7HXH/Kim et al. - 2021 - Fast calculation software for modified Look-Locker.pdf},
  journal = {BMC Medical Imaging},
  language = {en},
  number = {1},
}

@inproceedings{kim_robust_2019b,
  title = {Towards Robust Data-Driven Parallel Loop Scheduling Using {{Bayesian}} Optimization},
  booktitle = {Proceedings of the {{IEEE International Symposium}} on {{Modeling}}, {{Analysis}}, and {{Simulation}} of {{Computer}} and {{Telecommunication Systems}}},
  author = {Kim, Khu-rai and Kim, Youngjae and Park, Sungyong},
  year = {2019},
  month = oct,
  pages = {241--248},
  address = {{Rennes, FR}},
}

@article{son_gpu_2021,
  title = {A GPU Scheduling Framework to Accelerate Hyper-Parameter Optimization in Deep Learning Clusters},
  author = {Son, Jaewon and Yoo, Yonghyuk and Kim, Khu-rai and Kim, Youngjae and Lee, Kwonyong and Park, Sungyong},
  year = {2021},
  month = feb,
  volume = {10},
  pages = {350},
  abstract = {This paper proposes Hermes, a container-based preemptive GPU scheduling framework for accelerating hyper-parameter optimization in deep learning (DL) clusters. Hermes accelerates hyper-parameter optimization by time-sharing between DL jobs and prioritizing jobs with more promising hyper-parameter combinations. Hermes's scheduling policy is grounded on the observation that good hyper-parameter combinations converge quickly in the early phases of training. By giving higher priority to fast-converging containers, Hermes's GPU preemption mechanism can accelerate training. This enables users to find optimal hyper-parameters faster without losing the progress of a container. We have implemented Hermes over Kubernetes and compared its performance against existing scheduling frameworks. Experiments show that Hermes reduces the time for hyper-parameter optimization up to 4.04 times against previously proposed scheduling policies such as FIFO, round-robin (RR), and SLAQ, with minimal time-sharing overhead.},
  file = {/home/msca8h/Zotero/storage/SCZ8HI74/Son et al. - 2021 - A GPU Scheduling Framework to Accelerate Hyper-Par.pdf},
  journal = {Electronics},
  language = {en},
  number = {3},
}
